# Project_Data-analysis-on-Power-Station-Dataset
**client backgorund**  
The client is invited by a solar PV station company to inject capital in the Joint Vanture which invests on the new power stations,and he hopes to evaluate the return based on the market and economics analysis from estimating the electricity supply and demand in the following years.  

**Requirements**  
Decompose, downside and sample the big data for further analysis, including optimization modeling, machine learning and financial modeling.  

**Challenges**
- How much loss of information can we accept when reducung the size of big data?
- How much loss of information that the signals(demand & generation of electricity) drive investments are not distorted?    

**Our solution**  
There are several methods for data cleaning on the differnt fronts. Including handling missing values, scaling and normalization, parsing dates and chareacter encodings. With our methodology, we will generate the electricy demand dataset and power generating dataset for analysis. The way we are using is to downside the dataset as a smaller dataset that retains the key information of the orginial one, and breaks into 6 steps to complete.  

**KPI**  
- Achieve maximum reduction of Big Data. 
- Achieve minimum loss of inforamtion.
